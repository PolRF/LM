GPTLM(
  (token_embedding): Embedding(50304, 768)
  (blocks): Sequential(
    (0): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (1): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (2): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (3): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (4): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (5): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (6): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (7): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (8): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (9): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (10): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (11): AttentionBlock(
      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): DecoderMultiHeadAttention(
        (att): Linear(in_features=768, out_features=2304, bias=False)
        (linear_projection): Linear(in_features=768, out_features=768, bias=True)
        (projection_dropout): Dropout(p=0.2, inplace=False)
        (attn_dropout): Dropout(p=0.2, inplace=False)
      )
      (ffn): FFN(
        (net): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=3072, out_features=768, bias=True)
          (3): Dropout(p=0.2, inplace=False)
        )
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (lm_head): Linear(in_features=768, out_features=50304, bias=True)
)
162.3456 M parameters
